The goal of this paper is to describe the algorithm that we are using
in PeakSegPipeline::problem.target in order to quickly compute the
target inteval, by only evaluating FPOP a few O(log N) times, even
when there are hundreds/thousands of desired peaks/segments.

** TODOs

compute test error differences using the three different target
intervals.

** 17 Feb 2021

Updated [[file:figure-penalties-per-problem.R]] to additionally make a
plot of number of training examples (for the penalty learning problem) 
we can compute with partial method, as a function of the number of
training examples that we can compute in the same amount of time using
full method,

[[file:figure-penalties-per-problem-train.png]] 

Also a figure which shows how many problem.target iterations it takes
in order to get the absolute target change below a certain threshold,

[[file:figure-penalties-per-problem-maxit-thresh-hist.png]]


** 22 Sept 2020

[[file:figure-penalties-per-problem.R]] compares how many penalties you
can compute in a limited amount of time.

[[file:figure-penalties-per-problem.png]]

order.type=full means to first do an entire problem.target search
(compute several penalties) on the smallest labeled data set, then do
an entire search on the second smallest, etc.

order.type=partial means to do one iteration/penalty of the search
algorithm on each labeled data set first, then do a second iteration
on each, etc.

We can see that for a small amount of time the partial method results
in more computed penalties, but for a larger amount of time the full
method results in more computed penalties.

TODO hybrid method which stays up?

TODO compute test accuracy/AUC.

** 2 Feb 2018

[[file:FPOP.neuroblastoma.R]] computes the FPOP target interval,
gridsearch, and PDPA target interval, for the neuroblastoma data set.

[[file:figure-FPOP-gridsearch-compare.R]] plots the differences between
target intervals using proposed target interval search, and naive grid
search.

[[file:figure-FPOP-gridsearch-compare-limits.png]]

[[file:figure-FPOP-gridsearch-compare.png]]

** 1 Feb 2018

[[file:FPOP.gridsearch.R]] computes a target interval based on a grid of
values that spans the FPOP target intervals (on average the same
number of FPOP evaluations as the target interval algo, the idea is to
show that it gets sub-optimal error/intervals in the same amount of
computation time).

** 26 Jan 2018

[[file:figure-FPOP-PDPA-compare.R]] computes and plots differences between
the target intervals in FPOP and PDPA.

[[file:figure-FPOP-PDPA-compare.png]]

[[file:figure-FPOP-PDPA-compare-limits.png]]

** 19 Jan 2018

[[file:FPOP.models.R]] uses PeakSegPipeline to compute target intervals
for each labeled data set in the chip-seq benchmark. 

[[file:PDPA.models.R]] downloads precomputed PeakSegPDPA models and
computes target intervals for comparison with the FPOP models.
